# 你在网上用软件，软件在后台利用你

在我开始讲今天的故事之前，请先答应我一件事：不管接下来看到了什么，都不要生气！ 

准备好了吗？那咱开始吧！我要说的是美国社交网络巨头脸书公司（Facebook）最近干的一件事——他们的数据研究人员偷偷用近70万名用户做样本，在人们不知情的状况下，人为地控制了用户登录后看到的新鲜事列表，以此测试能不能用这种方式操控人类的喜怒哀乐…… 

为了保证研究的学术性，他们邀请了美国康奈尔大学和加州大学的学者执行这次操作。 

在2012年年初大约一周的时间里，近70万名用户登录社交网站后，面对的全是程序规定他们看到的内容。他们被机器随机分为两组，其中一组会看到好友圈中的“好消息”，这些新鲜事里大多包含“爱”“美好”或者“漂亮”这样的词汇，不管是照片还是留言，展现的都是快乐的情绪；而另外一组，刷出来的都是些让人头大的烦心事，满屏的内容充斥着“恶心”“伤害”以及“丑陋”这种字眼。 

在最新一期的《美国国家科学院院刊》上，研究人员公布了他们的研究结果。他们发现，看到的多是积极、正面的内容，用户转发乐观评论、视频等的次数就会大幅增加；但如果看到的都是负面消息，用户也跟着自暴自弃，在网站上骂骂咧咧，发表负面意见的频率远超过以往。这份报告的结论是：“网络的情绪状态具有传染性，人们只要接触到他人的情绪，就会在毫无察觉的状态下受其影响，转向这种主流情绪。” 

科学家们得出的这个结论倒还挺有启发意义的。我看到这则研究报告的时候，恰好刚浏览完当天的社会新闻，一下子明白了，为啥我现在一肚子气。 

可是，愣了好一会儿，我才觉得不对啊，这不是拿咱们当网络实验的小白鼠吗？我们在毫不知情的状况下，被屏幕上这个看似寻常的小小软件算计了，这么轻易地被它主导了喜怒哀乐？ 

跟我一样感到生气的有政客、律师。大家愤怒的点各不相同：有人生气被侵犯了知情权，有人讨厌丢掉了一个礼拜的隐私权。但在我看来，这场实验给我带来的最大伤害是一种恐惧，因为它让我面对了一种可能——你在网上用软件，软件在后台利用你！每一个登录网络的人，都有可能成为它的实验小鼠。这个机器会以“改进设备”为由，拿你的一举一动当数据，反过来把人类研究个遍！ 

得了，作为千千万万新闻工作者中的一员，我今天又贡献了一条坏消息。不过，我还是发自内心地希望你能够跳出脸书给我们设定的研究结果，不要被坏消息左右情绪。咱们不是在开头就说好了嘛，今天看到什么，都决不生气！