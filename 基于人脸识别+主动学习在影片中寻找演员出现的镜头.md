```python
import os
import json
import time
import face_recognition
from PIL import Image, ImageOps
import av
import shutil

# ---------------- 全局变量 ---------------- #
face_templates = []
compress_image_base_width = 640

# ---------------- 工具函数：调整和压缩图像 ---------------- #
def adjust_face_locations(face_locations, original_image_path):
    """
    根据原图和压缩后图像的宽度，调整人脸位置坐标。
    参数:
    - face_locations: 压缩图像中检测到的人脸位置列表，每个位置为(top, right, bottom, left)。
    - original_image_path: 原始图像路径。
    
    返回:
    - 调整后的人脸位置列表。
    """
    global compress_image_base_width
    original_image = Image.open(original_image_path)
    original_width, _ = original_image.size
    scale_w = original_width / compress_image_base_width

    adjusted_locations = []
    for location in face_locations:
        top, right, bottom, left = location
        adjusted_top = int(top * scale_w)
        adjusted_right = int(right * scale_w)
        adjusted_bottom = int(bottom * scale_w)
        adjusted_left = int(left * scale_w)
        adjusted_locations.append((adjusted_top, adjusted_right, adjusted_bottom, adjusted_left))
    return adjusted_locations

def compress_image(image_path, output_path):
    """
    将图像等比例压缩到指定宽度 (compress_image_base_width)，并保存到output_path。
    """
    global compress_image_base_width
    with Image.open(image_path) as img:
        w_percent = (compress_image_base_width / float(img.size[0]))
        h_size = int((float(img.size[1]) * float(w_percent)))
        img = img.resize((compress_image_base_width, h_size), Image.Resampling.LANCZOS)
        img = ImageOps.exif_transpose(img)
        # 检查图像模式是否为 RGBA
        if img.mode == 'RGBA':
            # 转换为 RGB 模式（会移除透明度）
            img = img.convert('RGB')
        img.save(output_path)

def save_face_images(imagepath, face_locations, save_dir):
    """
    识别并保存图片中的所有人脸，用于调试或其他用途。
    参数:
    - imagepath: 待处理的图片。
    - face_locations: 人脸位置列表，每个位置为一个元组 (top, right, bottom, left)。
    - save_dir: 保存裁剪的人脸图片的目录。
    """
    if not os.path.exists(save_dir):
        os.makedirs(save_dir)

    image = Image.open(imagepath)
    image = ImageOps.exif_transpose(image)

    for i, face_location in enumerate(face_locations):
        top, right, bottom, left = face_location
        face_image = image.crop((left, top, right, bottom))
        if face_image.mode == 'RGBA':
            face_image = face_image.convert('RGB')
        out_path = os.path.join(save_dir, f'face_{time.time()}.jpg')
        face_image.save(out_path)
        print(f"保存人脸图片: {out_path}")
    
    print(f"共找到 {len(face_locations)} 张人脸。")

# ---------------- 预处理模板（对已有模板进行特征提取） ---------------- #
def preprocess_face_templates(directory='./templates'):
    """
    对templates文件夹下的图片进行人脸位置检测和特征提取，并存储到face_templates列表中。
    """
    global face_templates
    for filename in os.listdir(directory):
        if not filename.lower().endswith(('jpg', 'jpeg', 'png')):
            continue
        if filename.endswith('min.jpg'):  # 跳过已压缩的文件
            continue
        
        # 原图路径
        original_path = os.path.join(directory, filename)
        # 压缩后的图片名称
        min_filename = filename.rsplit('.', 1)[0] + '_min.jpg'
        min_path = os.path.join(directory, min_filename)

        # 压缩原图并保存
        compress_image(original_path, min_path)
            
        # 在压缩图上检测人脸位置，然后换算回原图坐标
        image_compressed = face_recognition.load_image_file(min_path)
        face_locations = face_recognition.face_locations(image_compressed, model='hog')
        face_locations = adjust_face_locations(face_locations, original_path)
            
        # 使用原图获取特征向量（利用映射好的face_locations）
        image_original = face_recognition.load_image_file(original_path)
        face_encodings = face_recognition.face_encodings(image_original, 
                                                         known_face_locations=face_locations, 
                                                         model='small')
        for face_encoding in face_encodings:
            face_templates.append({
                'file_name': filename,
                'face_location': face_locations,
                'face_encoding': face_encoding
            })

# ---------------- 检测当前帧是否有已知演员人脸 ---------------- #
def check_actor_in_frame(sample_image_path, similarity_threshold=0.4):
    """
    给定一帧图像，判断是否出现了已在face_templates中的演员。
    如果任意一张模板的相似度 >= (1.00 - similarity_threshold) 则认为检测到演员。
    
    - sample_image_path: 帧图片的路径
    - similarity_threshold: 距离阈值，可根据实际需要调整，越小越严格
    
    返回: True/False 表明是否检测到演员
    """
    global face_templates
    min_filepath = sample_image_path.rsplit('.', 1)[0] + '_min.jpg'
    compress_image(sample_image_path, min_filepath)

    image_compressed = face_recognition.load_image_file(min_filepath)
    frame_face_locations = face_recognition.face_locations(image_compressed, model='hog')
    if not frame_face_locations:
        if os.path.exists(min_filepath):
            os.remove(min_filepath)
        return False
    
    # 将人脸位置映射回原图
    frame_face_locations = adjust_face_locations(frame_face_locations, sample_image_path)

    image_original = face_recognition.load_image_file(sample_image_path)
    frame_face_encodings = face_recognition.face_encodings(
        image_original, 
        known_face_locations=frame_face_locations, 
        model='small'
    )
    
    # 删除压缩文件
    if os.path.exists(min_filepath):
        os.remove(min_filepath)

    # 对每个检测到的人脸与模板进行比对
    for i, frame_encoding in enumerate(frame_face_encodings):
        face_encodings_list = [template['face_encoding'] for template in face_templates]
        distances = face_recognition.face_distance(face_encodings_list, frame_encoding)
        for distance in distances:
            similarity = 1.00 - distance
            if similarity >= (1.00 - similarity_threshold):
                # debug
                print(f"检测到演员，相似度: {similarity:.2f}")

                # ========== 新增功能 1：主动学习，加入新的模板 ==========
                add_new_template(
                    image_path=sample_image_path,
                    templates_dir='./templates',
                    face_locations=frame_face_locations,
                    face_location=frame_face_locations[i],
                    face_encoding=frame_encoding
                )

                return True
    return False

# =============== 新增功能 1：主动学习，将帧图像添加到模板并更新 face_templates =============== #
def add_new_template(image_path, templates_dir='./templates',face_locations=None,face_location=None,face_encoding=None):
    """
    将包含演员人脸的整张原图复制到 templates_dir 下；
    然后检测其中的人脸并提取向量，追加到 face_templates。
    """
    global face_templates

    if not os.path.exists(templates_dir):
        os.makedirs(templates_dir)

    image = Image.open(image_path)
    image = ImageOps.exif_transpose(image)

    base_name = os.path.basename(image_path)
    out_path = os.path.join(templates_dir,base_name)
    
    top, right, bottom, left = face_location
    face_image = image.crop((left, top, right, bottom))
    if face_image.mode == 'RGBA':
        face_image = face_image.convert('RGB')
    face_image.save(out_path)
    print(f"主动学习：已添加人脸模板 {out_path}")
    
    # 复制帧图像到 ./debugface2
    if not os.path.exists('./debugface2'):
        os.makedirs('./debugface2')
    new_template_path = os.path.join('./debugface2', base_name)
    shutil.copyfile(image_path, new_template_path)
    print(f"debug：已复制帧图像到 ./debugface2/{base_name}")
    

    # 将新提取的向量加入到 face_templates
    face_templates.append({
        'file_name': base_name,
        'face_location': face_locations,
        'face_encoding': face_encoding
    })
    print(f"主动学习：为 {base_name} 提取向量，已加入全局模板。")

# =============== 新增功能 2：搜索指定时间点附近的演员出现片段 =============== #
def check_actor_in_frame_at_time(video_path, target_time, similarity_threshold=0.4):
    """
    在指定 time 点打开视频并获取最接近的关键帧，然后判断该帧是否出现演员。
    返回 True/False。
    """
    try:
        container = av.open(video_path)
        video_stream = container.streams.video[0]

        # 将时间转换为PTS（流基准时间）
        target_pts = int(target_time / video_stream.time_base)
        container.seek(
            offset=target_pts,
            stream=video_stream,
            backward=True,
            any_frame=False
        )

        # 解码第一帧
        frame = next(container.decode(video=0))
        real_time = float(frame.pts * video_stream.time_base)

        # 保存到临时文件
        temp_frame_path = f"temp_search_{int(real_time*1000)}.jpg"
        img = frame.to_image()
        img = ImageOps.exif_transpose(img)
        img.save(temp_frame_path)

        # 调用已有的人脸检测
        found = check_actor_in_frame(temp_frame_path, similarity_threshold=similarity_threshold)

        # 清理
        if os.path.exists(temp_frame_path):
            os.remove(temp_frame_path)
        container.close()
        return found
    except Exception as e:
        # 如果遇到如 EOF、解码失败等情况直接返回 False
        return False

def search_actor_range(video_path, initial_time, max_gap=30.0, step=1.0, similarity_threshold=0.4):
    """
    从 initial_time 点开始，分别向前和向后搜索演员出现的连续片段。
    当连续没有检测到演员超过 max_gap 秒时，停止搜索。
    step 为搜索步长，默认 1 秒。
    返回 (start_time, end_time)。
    """
    # 获取视频时长
    container = av.open(video_path)
    video_stream = container.streams.video[0]
    s_c_duration = video_stream.duration if video_stream.duration else container.duration
    duration = float(s_c_duration * video_stream.time_base)
    container.close()

    # 先向前搜索，找到结束时间
    end_time = initial_time
    not_found_accum = 0.0
    t = initial_time
    while True:
        t += step
        if t > duration:
            break
        found = check_actor_in_frame_at_time(video_path, t, similarity_threshold=similarity_threshold)
        if found:
            end_time = t
            not_found_accum = 0.0
        else:
            not_found_accum += step
            if not_found_accum >= max_gap:
                break

    # 再向后回溯到 initial_time，反向搜索找到开始时间
    start_time = initial_time
    not_found_accum = 0.0
    t = initial_time
    while True:
        t -= step
        if t < 0:
            break
        found = check_actor_in_frame_at_time(video_path, t, similarity_threshold=similarity_threshold)
        if found:
            start_time = t
            not_found_accum = 0.0
        else:
            not_found_accum += step
            if not_found_accum >= max_gap:
                break

    return (start_time, end_time)

# ---------------- 脚本入口：打开视频，循环抽帧并查找演员出现时间点 + 新增功能 ---------------- #
def main():
    # 1. 预处理模板
    preprocess_face_templates(directory='./templates')
    print("模板预处理完成，已加载人脸模板数量：", len(face_templates))

    # 2. 读取视频文件（请根据实际路径修改）
    video_path = "1091578122_sr1-1-100035.m4s"
    
    container = av.open(video_path)
    video_stream = container.streams.video[0]
    fps = float(video_stream.average_rate)
    s_c_duration = video_stream.duration if video_stream.duration else container.duration
    duration = float(s_c_duration * video_stream.time_base)
    total_frames = video_stream.frames  
    if total_frames is None or total_frames <= 0:
        total_frames = int(duration * fps)

    print(f"视频总帧数: {total_frames}, 帧率: {fps}, 时长: {duration:.2f}秒")

    # 每隔多少秒抽取一帧
    interval_seconds = 30.0

    # 记录演员出现的时间区间
    found_times = []

    current_time = 0.0
    while current_time <= duration:
        try:
            # 将时间转换为流的基准时间单位
            target_pts = int(current_time / video_stream.time_base)
            container.seek(
                offset=target_pts,
                stream=video_stream,
                backward=True,
                any_frame=False
            )
            frame = next(container.decode(video=0))
            current_time = float(frame.pts * video_stream.time_base)

            # 转成图像并保存到临时文件
            img = frame.to_image()
            img = ImageOps.exif_transpose(img)
            temp_frame_path = f"frame_{int(current_time)}.jpg"
            img.save(temp_frame_path)

            # 检测是否出现已知演员
            if check_actor_in_frame(temp_frame_path, similarity_threshold=0.4):
                print(f"检测到演员，当前时间: {current_time:.2f}秒")
                # 移动临时文件到调试目录
                debug_dir = "./debugface2"
                if not os.path.exists(debug_dir):
                    os.makedirs(debug_dir)
                debug_path = os.path.join(debug_dir, os.path.basename(temp_frame_path))
                os.rename(temp_frame_path, debug_path)
                print(f"画面已保存至: {debug_path}")

                # ========== 新增功能 2：搜索该演员出现的起止时间 ==========
                start_time, end_time = search_actor_range(
                    video_path, 
                    current_time, 
                    max_gap=30.0,
                    step=1.0, 
                    similarity_threshold=0.4
                )
                found_times.append((start_time, end_time))
                print(f"在 {current_time:.2f} 秒检测到演员，其前后出现的连续时间段为：({start_time:.2f}, {end_time:.2f})")

            else:
                # 删除临时帧文件
                if os.path.exists(temp_frame_path):
                    os.remove(temp_frame_path)

            print(f"当前时间点抽帧: {current_time:.2f}秒")
        except (av.AVError, StopIteration) as e:
            print(f"在时间点 {current_time:.2f} 秒处，处理失败: {str(e)}")
            break

        current_time += interval_seconds

    container.close()

    # 3. 将识别结果写入 JSON 文件
    output_data = {
        "video_path": video_path,
        "found_times": found_times,  # 保存为一组 (start, end) 的列表
        "interval_seconds": interval_seconds,
        "total_duration": duration
    }
    with open("found_times.json", "w", encoding="utf-8") as f:
        json.dump(output_data, f, ensure_ascii=False, indent=4)

    print("识别完成，结果已写入 found_times.json")
    print("演员出现的时间区间(秒)：", found_times)

if __name__ == "__main__":
    main()

```
